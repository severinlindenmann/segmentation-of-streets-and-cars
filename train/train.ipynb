{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available:  True\n",
      "Device name: NVIDIA GeForce RTX 2080 SUPER\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchvision.datasets import Cityscapes\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# pyton 3.9.11 / cuda / windows\n",
    "# pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu121 \n",
    "# ipython kernel install --name \"cuda-train\" --user\n",
    "# pip install ipython matplotlib\n",
    "print(\"Cuda available: \", torch.cuda.is_available())\n",
    "print(\"Device name:\", torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = '/Users/severin/Documents/Projects/segmentation/cityscapes'\n",
    "data_path = \"Q:/Projects/u-net-segmentation-of-streets-and-cars/train/cityscapes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_image(img):\n",
    "    return torch.from_numpy(np.array(img)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your data transformation (you might need to customize these)\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize images\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "])\n",
    "\n",
    "def transform_image(img):\n",
    "    return torch.from_numpy(np.array(img)).long()\n",
    "\n",
    "# Define your target transformation\n",
    "target_transforms = transforms.Compose([\n",
    " transforms.Resize((256, 256)), # Resize target\n",
    " transforms.Lambda(lambda img: torch.Tensor(np.array(img))), \n",
    "])\n",
    "\n",
    "# Create Cityscapes dataset instance\n",
    "dataset = Cityscapes(root=data_path, split='train', mode='fine', \n",
    "                     target_type='semantic', transform=data_transforms, \n",
    "                     target_transform=target_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the first image and its segmentation mask\n",
    "img, smnt = dataset[0]\n",
    "\n",
    "# Convert tensors to numpy arrays\n",
    "img_np = img.permute(1, 2, 0).numpy()\n",
    "smnt_np = np.array(smnt)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Display the image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Image')\n",
    "plt.imshow(img_np)\n",
    "plt.axis('off')\n",
    "\n",
    "# Display the segmentation mask\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Segmentation Mask')\n",
    "plt.imshow(smnt_np)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for easy iteration\n",
    "batch_size = 32 \n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "                  \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # Use GPU if available\n",
    "\n",
    "# Load a pretrained model\n",
    "model = models.segmentation.fcn_resnet101(weights='DEFAULT') # Load a pretrained FCN-ResNet101 \n",
    "\n",
    "# Replace the classifier part for your task\n",
    "num_classes = len(Cityscapes.classes)\n",
    "model.classifier[-1] = nn.Conv2d(512, num_classes, kernel_size=(1, 1), stride=(1, 1)) \n",
    "\n",
    "# Load previously saved model weights (for example, epoch 1)\n",
    "checkpoint = torch.load('model_weights.pth')  # Change the file path to your desired checkpoint\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "# Ensure the model is in training mode\n",
    "model.train()\n",
    "\n",
    "# Move the model to the GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/∞\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "num_epochs = None\n",
    "epoch = 0\n",
    "\n",
    "while True:\n",
    "    epoch += 1\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs if num_epochs else \"∞\"))\n",
    "    print('-' * 10)\n",
    "    \n",
    "    total_batches = len(dataloader)\n",
    "    batch_count = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    for inputs, labels in dataloader:\n",
    "        batch_count += 1\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).long()  # Convert the type of labels to Long\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs['out']\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_loss = loss.item()\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        print('Batch {}/{} - Loss: {:.4f}'.format(batch_count, total_batches, batch_loss))\n",
    "\n",
    "        del loss, outputs, labels  # Manually delete tensors to free memory\n",
    "\n",
    "    average_loss = total_loss / total_batches\n",
    "\n",
    "    print('Epoch completed. Average Loss: {:.4f}'.format(average_loss))\n",
    "\n",
    "    # Save model weights after each epoch\n",
    "    torch.save(model.state_dict(), f'model_weights_epoch_{epoch}.pth')\n",
    "\n",
    "    if num_epochs and epoch >= num_epochs:\n",
    "        break\n",
    "\n",
    "print('Training completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the state dictionary\n",
    "state_dict = torch.load('model_weights_v2.pth')\n",
    "\n",
    "# Remove keys related to auxiliary classifiers from the state dictionary\n",
    "state_dict = {k: v for k, v in state_dict.items() if 'aux_classifier' not in k}\n",
    "\n",
    "# Create your model and load the modified state dictionary\n",
    "num_classes = len(Cityscapes.classes)\n",
    "model = models.segmentation.fcn_resnet101(weights='DEFAULT', num_classes=num_classes)\n",
    "model.load_state_dict(state_dict, strict=False)  # Set strict=False to skip missing keys\n",
    "\n",
    "# Load the input image\n",
    "input_image = Image.open(f'{data_path}/leftImg8bit/train/zurich/zurich_000017_000019_leftImg8bit.png')\n",
    "\n",
    "# Apply the necessary transformations\n",
    "input_tensor = data_transforms(input_image).unsqueeze(0)\n",
    "\n",
    "# Perform prediction\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_tensor)['out']  # Correct 'inputs' to 'input_tensor'\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# Convert the predicted image tensor to a numpy array\n",
    "predicted_numpy = predicted.squeeze(0).cpu().numpy()\n",
    "\n",
    "# Define label colors for 35 classes (replace this with your color mappings)\n",
    "label_colors_35_classes = np.random.randint(0, 256, size=(35, 3), dtype=np.uint8)\n",
    "\n",
    "# Convert the predicted segmentation mask to a colored mask\n",
    "colored_mask = label_colors_35_classes[predicted_numpy]\n",
    "\n",
    "# Plot the original input image and the colored mask\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].imshow(input_image)\n",
    "axs[0].axis('off')\n",
    "axs[0].set_title('Input Image')\n",
    "axs[1].imshow(colored_mask)\n",
    "axs[1].axis('off')\n",
    "axs[1].set_title('Predicted Segmentation Mask')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-train",
   "language": "python",
   "name": "cuda-train"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
