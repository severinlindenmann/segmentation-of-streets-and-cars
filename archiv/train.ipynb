{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6b/xtl7vy6938n0dnfml7qyq69h0000gn/T/ipykernel_86602/204373724.py:22: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  resized_image = image.resize(temp_size, Image.ANTIALIAS)\n",
      "/var/folders/6b/xtl7vy6938n0dnfml7qyq69h0000gn/T/ipykernel_86602/204373724.py:37: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  resized_image = resized_image.resize((512, 512), Image.ANTIALIAS)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_image(image, output_image_path):\n",
    "    # Size of the trained model\n",
    "    new_size = (2048, 1024)\n",
    "\n",
    "    # Calculate the aspect ratio of the image\n",
    "    original_ratio = image.size[0] / image.size[1]\n",
    "    new_ratio = new_size[0] / new_size[1]\n",
    "\n",
    "    # Resize the image to fit within the new dimensions while preserving aspect ratio and crop if necessary\n",
    "    if original_ratio >= new_ratio:\n",
    "        temp_height = new_size[1]\n",
    "        temp_width = round(new_size[1] * original_ratio)\n",
    "    else:\n",
    "        temp_width = new_size[0]\n",
    "        temp_height = round(new_size[0] / original_ratio)\n",
    "        \n",
    "    temp_size = (temp_width, temp_height)\n",
    "    resized_image = image.resize(temp_size, Image.ANTIALIAS)\n",
    "    \n",
    "    # Calculate the cropping area\n",
    "    left = (resized_image.width - new_size[0]) / 2\n",
    "    top = (resized_image.height - new_size[1]) / 2\n",
    "    right = (resized_image.width + new_size[0]) / 2\n",
    "    bottom = (resized_image.height + new_size[1]) / 2\n",
    "\n",
    "    # Crop the image\n",
    "    resized_image = resized_image.crop((left, top, right, bottom))\n",
    "\n",
    "    # Convert the image to greyscale\n",
    "    resized_image = resized_image.convert(\"L\")\n",
    "\n",
    "    # Resize image to 512 x 512\n",
    "    resized_image = resized_image.resize((512, 512), Image.ANTIALIAS)\n",
    "\n",
    "    # Save the result\n",
    "    resized_image.save(output_image_path, format=\"PNG\")\n",
    "\n",
    "def preprocess_images_and_masks(input_images_folder, input_masks_folder, output_dir_images, output_dir_masks):\n",
    "    # Create output directories if they don't exist\n",
    "    os.makedirs(output_dir_images, exist_ok=True)\n",
    "    os.makedirs(output_dir_masks, exist_ok=True)\n",
    "\n",
    "    image_files = sorted(os.listdir(input_images_folder))\n",
    "    mask_files = sorted(os.listdir(input_masks_folder))\n",
    "\n",
    "    for img_file, mask_file in zip(image_files, mask_files):\n",
    "        img_path = os.path.join(input_images_folder, img_file)\n",
    "        mask_path = os.path.join(input_masks_folder, mask_file)\n",
    "\n",
    "        # Open images\n",
    "        image = Image.open(img_path)\n",
    "        mask = Image.open(mask_path)\n",
    "\n",
    "        # Preprocess images and masks\n",
    "        preprocess_image(image, os.path.join(output_dir_images, f\"{os.path.splitext(img_file)[0]}_512x512_grey.png\"))\n",
    "        preprocess_image(mask, os.path.join(output_dir_masks, f\"{os.path.splitext(mask_file)[0]}_512x512_grey.png\"))\n",
    "\n",
    "# Input and output directories\n",
    "input_images_folder = 'images'\n",
    "input_masks_folder = 'masks'\n",
    "output_dir_images = 'images_resized'\n",
    "output_dir_masks = 'masks_resized'\n",
    "\n",
    "# Preprocess images and masks\n",
    "preprocess_images_and_masks(input_images_folder, input_masks_folder, output_dir_images, output_dir_masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 10:09:20.624681: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [10]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    }
   ],
   "source": [
    "def load_image_and_mask(image_path, mask_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image, channels=1)  # Assuming grayscale images\n",
    "    image = tf.image.resize(image, (512, 512))  # Resize if needed\n",
    "    image = image / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    mask = tf.image.decode_png(mask, channels=1)  # Assuming grayscale masks\n",
    "    mask = tf.image.resize(mask, (512, 512))  # Resize if needed\n",
    "    mask = mask / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "    return image, mask\n",
    "\n",
    "def load_images_and_masks(image_dir, mask_dir, subset_size=None):\n",
    "    image_paths = sorted([os.path.join(image_dir, file) for file in os.listdir(image_dir)])[:subset_size]\n",
    "    mask_paths = sorted([os.path.join(mask_dir, file) for file in os.listdir(mask_dir)])[:subset_size]\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, mask_paths))\n",
    "    dataset = dataset.map(load_image_and_mask, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# Path to your images and masks directories\n",
    "image_directory = 'images_resized'\n",
    "mask_directory = 'masks_resized'\n",
    "\n",
    "# Load a subset of images and masks into a TensorFlow dataset\n",
    "subset_size = 10  # Define the subset size\n",
    "images_and_masks_subset = load_images_and_masks(image_directory, mask_directory, subset_size=subset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 10:13:43.099790: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [10]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-11-16 10:13:43.100015: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [10]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 0.6682 - accuracy: 0.2671"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 10:13:50.156879: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [10]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-11-16 10:13:50.157047: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [10]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 4s/step - loss: 0.6682 - accuracy: 0.2671 - val_loss: 0.5664 - val_accuracy: 0.4587\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 7s 4s/step - loss: 0.5049 - accuracy: 0.3681 - val_loss: 0.2651 - val_accuracy: 0.3595\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 7s 4s/step - loss: 0.2320 - accuracy: 0.3429 - val_loss: 0.3040 - val_accuracy: 0.3668\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 7s 4s/step - loss: 0.2724 - accuracy: 0.3429 - val_loss: 0.2732 - val_accuracy: 0.4671\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 7s 4s/step - loss: 0.2909 - accuracy: 0.3582 - val_loss: 0.1636 - val_accuracy: 0.3648\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 7s 4s/step - loss: 0.1982 - accuracy: 0.3676 - val_loss: 0.2234 - val_accuracy: 0.3732\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 7s 4s/step - loss: 0.2465 - accuracy: 0.3586 - val_loss: 0.2380 - val_accuracy: 0.4241\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.2193 - accuracy: 0.3570 - val_loss: 0.1906 - val_accuracy: 0.3751\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.2130 - accuracy: 0.3833 - val_loss: 0.1983 - val_accuracy: 0.4671\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.2200 - accuracy: 0.3450 - val_loss: 0.1933 - val_accuracy: 0.4128\n",
      "1/1 [==============================] - 1s 573ms/step - loss: 0.1434 - accuracy: 0.3601\n",
      "Validation Loss: 0.1434054672718048, Validation Accuracy: 0.3600749969482422\n"
     ]
    }
   ],
   "source": [
    "# Split Data\n",
    "def split_dataset(dataset, train_size=0.8, shuffle=True):\n",
    "    dataset_size = tf.data.experimental.cardinality(dataset).numpy()\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=dataset_size)\n",
    "    train_dataset = dataset.take(int(train_size * dataset_size))\n",
    "    val_dataset = dataset.skip(int(train_size * dataset_size))\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "train_dataset, val_dataset = split_dataset(images_and_masks_subset)\n",
    "\n",
    "# U-Net Model\n",
    "def unet_model(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    # Bottleneck\n",
    "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "\n",
    "    # Decoder\n",
    "    up4 = layers.Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(conv3)\n",
    "    merge4 = layers.concatenate([up4, conv2], axis=3)\n",
    "    conv4 = layers.Conv2D(128, 3, activation='relu', padding='same')(merge4)\n",
    "\n",
    "    up5 = layers.Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(conv4)\n",
    "    merge5 = layers.concatenate([up5, conv1], axis=3)\n",
    "    conv5 = layers.Conv2D(64, 3, activation='relu', padding='same')(merge5)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = layers.Conv2D(1, 1, activation='sigmoid')(conv5)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Batch Size\n",
    "batch_size = 4\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "# Instantiate the U-Net model\n",
    "input_shape = (512, 512, 1)  # Input shape for grayscale images\n",
    "model = unet_model(input_shape)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "model.fit(train_dataset, \n",
    "          epochs=10, \n",
    "          validation_data=val_dataset)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(val_dataset)\n",
    "print(f'Validation Loss: {loss}, Validation Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 277ms/step\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Function to load and preprocess the image\n",
    "def load_and_preprocess_image(image_path, input_shape):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_png(img, channels=1)\n",
    "    img = tf.image.resize(img, input_shape)\n",
    "    img = img / 255.0\n",
    "    img = tf.expand_dims(img, axis=0)  # Add an extra dimension for the batch size\n",
    "    return img\n",
    "\n",
    "# Function to save the mask as an image\n",
    "def save_mask_image(mask, save_path):\n",
    "    # Postprocess the predicted mask\n",
    "    mask = tf.squeeze(mask, axis=0)  # Remove the batch size dimension\n",
    "    mask = (mask > 0.5)  # Thresholding the mask\n",
    "    \n",
    "    # Ensure we have a channel dimension\n",
    "    if len(mask.shape) == 2:\n",
    "        mask = mask[..., tf.newaxis]\n",
    "\n",
    "    # Save the mask as an image\n",
    "    mask_img = tf.keras.preprocessing.image.array_to_img(mask)\n",
    "    mask_img.save(save_path)\n",
    "\n",
    "# Load an example image\n",
    "image_path = '/Users/severin/Documents/GitHub/u-net-segmentation-of-streets-and-cars/images_resized/zurich_000004_000019_leftImg8bit_512x512_grey.png'  # Replace with your image path\n",
    "img = load_and_preprocess_image(image_path, input_shape=(512, 512))\n",
    "\n",
    "# Predict the mask using the trained model\n",
    "pred_mask = model.predict(img)\n",
    "\n",
    "# Save the predicted mask as an image\n",
    "mask_save_path = 'predicted_mask.png'  # Replace with your save path\n",
    "save_mask_image(pred_mask, mask_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
